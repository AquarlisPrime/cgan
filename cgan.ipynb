import os
import cv2
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Concatenate, Activation, Flatten, Dense
from tensorflow.keras.optimizers import Adam
import tensorflow.compat.v1 as tf

def load_dataset(folder_path):
    input_images = []
    conditioning_images = []
    target_images = []

    for file_name in os.listdir(folder_path):
        if file_name.startswith("input_"):
            input_path = os.path.join(folder_path, file_name)
            target_path = os.path.join(folder_path, file_name.replace("input_", "target_"))
            conditioning_path = os.path.join(folder_path, file_name.replace("input_", "conditioning_"))


            input_image = cv2.imread(input_path)
            target_image = cv2.imread(target_path)
            conditioning_image = cv2.imread(conditioning_path)

            # Resize images if needed
            input_image = cv2.resize(input_image, (64, 64))
            target_image = cv2.resize(target_image, (64, 64))
            conditioning_image = cv2.resize(conditioning_image, (64, 64))


            input_images.append(input_image / 255.0)
            target_images.append(target_image / 255.0)
            conditioning_images.append(conditioning_image / 255.0)

    return np.array(input_images), np.array(conditioning_images), np.array(target_images)

def build_generator(input_shape):
    inputs = Input(shape=input_shape)
    conditioning_inputs = Input(shape=input_shape)

    # Encoder
    x = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(inputs)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    
    # Add more Conv2D layers with BatchNormalization and LeakyReLU
    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    
    # Add more Conv2D layers with BatchNormalization and LeakyReLU
    x = Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    # Decoder
    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    
    # Add more Conv2DTranspose layers with BatchNormalization and LeakyReLU
    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    
    # Add more Conv2DTranspose layers with BatchNormalization and LeakyReLU
    x = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    # Concatenate conditioning_inputs
    x = Concatenate()([x, conditioning_inputs])

    outputs = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)

    generator = Model([inputs, conditioning_inputs], outputs)
    return generator

def generate_merged_image(generator, input_image, conditioning_image):
    input_image = np.expand_dims(input_image, axis=0)
    conditioning_image = np.expand_dims(conditioning_image, axis=0)

    generated_image = generator.predict([input_image, conditioning_image])

    # Post-process generated image if needed (e.g., rescale pixel values)
    generated_image = (generated_image * 255).astype(np.uint8)

    return generated_image.squeeze()


def build_discriminator(input_shape):
    inputs = Input(shape=input_shape)
    conditioning_inputs = Input(shape=input_shape)

    # Concatenate inputs and conditioning_inputs
    x = Concatenate()([inputs, conditioning_inputs])

    # Add Conv2D layers with LeakyReLU and Dropout
    x = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Conv2D(512, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Flatten()(x)
    outputs = Dense(1, activation='sigmoid')(x)

    discriminator = Model([inputs, conditioning_inputs], outputs)
    return discriminator

def build_cgan_model(input_shape):
    generator = build_generator(input_shape)
    discriminator = build_discriminator(input_shape)

    input_image = Input(shape=input_shape)
    conditioning_image = Input(shape=input_shape)

    generated_image = generator([input_image, conditioning_image])

    discriminator.trainable = False
    validity = discriminator([generated_image, conditioning_image])

    cgan_model = Model(inputs=[input_image, conditioning_image], outputs=validity)
    cgan_model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])

    return cgan_model

input_images, _, _ = load_dataset(r'C:\Users\Dell\Downloads\archive (1)')

# Print the shape of input_images
print("Shape of input_images:", input_images.shape)

def train_cgan(generator, discriminator, cgan_model, input_images, conditioning_images, target_images, epochs, batch_size):
    for epoch in range(epochs):
        idx = np.random.randint(0, input_images.shape[0], batch_size)
        input_batch = input_images[idx]
        conditioning_batch = conditioning_images[idx]
        target_batch = target_images[idx]

        generated_images = generator.predict([input_batch, conditioning_batch])

        d_loss_real = discriminator.train_on_batch([target_batch, conditioning_batch], np.ones((batch_size, 1)))
        d_loss_fake = discriminator.train_on_batch([generated_images, conditioning_batch], np.zeros((batch_size, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        g_loss = cgan_model.train_on_batch([input_batch, conditioning_batch], np.ones((batch_size, 1)))

        print(f"Epoch {epoch + 1}, [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss[0]} | G accuracy: {100 * g_loss[1]}]")

def generate_merged_image(generator, input_image, conditioning_image):
    input_image = np.expand_dims(input_image, axis=0)
    conditioning_image = np.expand_dims(conditioning_image, axis=0)

    generated_image = generator.predict([input_image, conditioning_image])

    # Post-process generated image if needed (e.g., rescale pixel values)
    generated_image = (generated_image * 255).astype(np.uint8)

    return generated_image.squeeze()

# Suppress the deprecation warning
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

# Load dataset
input_images, conditioning_images, target_images = load_dataset(r'C:\Users\Dell\Downloads\archive (1)')

# Build the model
input_shape = (64, 64, 3)
generator = build_generator(input_shape)
discriminator = build_discriminator(input_shape)
cgan_model = build_cgan_model(input_shape)

# print summary
generator.summary()
discriminator.summary()
cgan_model.summary()

batch_size = 32  # Define batch size


print(input_images.shape)
print("Shape of input_images:", input_images.shape)
print("Batch size:", batch_size)
print("Maximum index for random selection:", input_images.shape[0] - 1)

# Train the model
epochs = 100
batch_size = 32
input_images, conditioning_images, target_images = load_dataset(r'C:\Users\Dell\Downloads\archive (1)')
train_cgan(generator, discriminator, cgan_model, input_images, conditioning_images, target_images, epochs, batch_size)


# Save the model
model_save_path = r'C:\Users\Dell\Desktop\OpenCV\merge img\cGAN.py.h5'
cgan_model.save(model_save_path)
print(f"Model saved to {model_save_path}")
